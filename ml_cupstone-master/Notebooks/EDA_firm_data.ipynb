{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "# from scipy.optimize import curve_fit\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "import sklearn.preprocessing as prep\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "from rfpimp import dropcol_importances\n",
    "from rfpimp import importances\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_bar_diagram(ax, data, nested=False, plots_labels=None, plots_colors=None, bar_labels='', width=0.4, \n",
    "                     trend_line=False, trend_order=1, trend_color=None, \n",
    "                     title='', length_label='', tick_labels='', tick_axis_label='',\n",
    "                     orient='v', legend_loc=None, spines=None):\n",
    "    \"\"\"\n",
    "    Plots single or multiple bar diagrams with data labels on top(aside) of the bars\n",
    "    :param ax: matplotlib axes\n",
    "    :param data: pandas DataFrame where rows correspond to bar plots and columns correspond to data labels (columns in data)\n",
    "    :param nested: boolean. If True, bar plots are plotted on top of each other. If False bar plots are plotted besides each other\n",
    "    :param bar_labels: pandas DataFrame. labels over the bars. Should be same shape as data\n",
    "    :param width: float. Bar width\n",
    "    :param title: string. Plot title\n",
    "    :param length_label: bar height/width axis label\n",
    "    :param spines: dictionary of booleans. indicates to plot borders or not. Keys=['left', 'right', 'top', 'bottom'], values=True/False\n",
    "    :param orient: string. Bar orientation: 'v'-vertical; 'h'-horisontal\n",
    "    \"\"\"\n",
    "    bars = list(data.index)\n",
    "    cols = list(data.columns)\n",
    "    cells = data.values.tolist()\n",
    "\n",
    "    if bar_labels is not None:\n",
    "        labels = []\n",
    "        for i, lab in enumerate(bars):\n",
    "            if bar_labels=='':\n",
    "                labels.append([f\"{j:.4f}\" for j in cells[i]])\n",
    "            else:\n",
    "                labels.append(bar_labels[i])\n",
    "#             labels = ([f\"{j:.4f}\" for j in cells[i]] if bar_labels=='' else bar_labels[i])\n",
    "\n",
    "    if orient == 'v':\n",
    "        for i, lab in enumerate(bars):\n",
    "            label = (bars[i] if plots_labels is None else plots_labels[i])\n",
    "            color = ('r' if plots_colors is None else plots_colors[i])\n",
    "            x = np.arange(len(cols))\n",
    "            bar = ax.bar(x=x + width * (i - len(bars) / 2), height=cells[i], width=width,\n",
    "                         label=label,\n",
    "                         color=color,\n",
    "                         align=('center' if nested else 'edge'))\n",
    "            \n",
    "            if trend_line:\n",
    "                trend_color = (color if trend_color is None else trend_color[i])\n",
    "                _x = np.arange(len(cols))\n",
    "                _y = cells[i]\n",
    "                _z = np.polyfit(_x, _y, trend_order)\n",
    "                _p = np.poly1d(_z)\n",
    "                trend = ax.plot(_x, _p(_x), color=color, linestyle='--', linewidth=2.5)\n",
    "            \n",
    "            if bar_labels is not None:\n",
    "                autolabel(bar, ax, labels[i], oriented='v')\n",
    "\n",
    "        ax.set_xticks(np.arange(len(cols)))\n",
    "        if tick_labels=='':\n",
    "            ax.set_xticklabels(cols)\n",
    "        else:\n",
    "            ax.set_xticklabels(tick_labels)\n",
    "        if not length_label=='':\n",
    "            ax.set_ylabel(length_label, fontsize=12, fontweight='bold')\n",
    "        if not tick_axis_label=='':\n",
    "            ax.set_xlabel(tick_axis_label, fontsize=12, fontweight='bold')\n",
    "    elif orient == 'h':\n",
    "        for i, lab in enumerate(bars):\n",
    "            label = (bars[i] if plots_labels is None else plots_labels[i])\n",
    "            y = np.arange(len(cols))\n",
    "            height = width\n",
    "            bar = ax.barh(y=y + height * (i - len(bars) / 2), width=cells[i], height=width,\n",
    "                          label=label,\n",
    "                          color=plots_colors[i],\n",
    "                          align=('center' if nested else 'edge'))\n",
    "            \n",
    "            if trend_line:\n",
    "                trend_color = (color if trend_color is None else trend_color[i])\n",
    "                _x = np.arange(len(cols))\n",
    "                _y = cells[i]\n",
    "                _z = np.polyfit(_x, _y, trend_order)\n",
    "                _p = np.poly1d(_z)\n",
    "                trend = ax.plot(_x, _p(_x), color=color, linestyle='--', linewidth=2.5)\n",
    "            \n",
    "            if bar_labels is not None:\n",
    "                autolabel(bar, ax, labels[i], oriented='v')\n",
    "            if bar_labels is not None:\n",
    "                autolabel(bar, ax, labels[i], oriented='h')\n",
    "\n",
    "        ax.set_yticks(np.arange(len(cols)))\n",
    "        if tick_labels=='':\n",
    "            ax.set_yticklabels(cols)\n",
    "        else:\n",
    "            ax.set_yticklabels(tick_labels)\n",
    "        if not length_label=='':\n",
    "            ax.set_xlabel(length_label, fontsize=12, fontweight='bold')\n",
    "        if not tick_axis_label=='':\n",
    "            ax.set_ylabel(tick_axis_label, fontsize=12, fontweight='bold')\n",
    "    else:\n",
    "        raise ValueError('orient parameter value error. expected v or h ')\n",
    "\n",
    "    if not title == '':\n",
    "        ttl = ax.title\n",
    "        ttl.set_position([.5, 1.07])\n",
    "        ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    if legend_loc is not None:\n",
    "        ax.legend(loc=legend_loc)\n",
    "    else:\n",
    "        ax.legend().set_visible(False)\n",
    "\n",
    "    if spines is None:\n",
    "        spines = {'left': True,\n",
    "                  'right': True,\n",
    "                  'top': True,\n",
    "                  'bottom': True}\n",
    "    for i in list(spines.keys()):\n",
    "        ax.spines[i].set_visible(spines[i])\n",
    "        \n",
    "    ax.grid(True, axis='y')\n",
    "\n",
    "def autolabel(bars, ax, labels, oriented='v'):\n",
    "    \"\"\"Attach a text label displaying its height/width (depends of orientation).\"\"\"\n",
    "    for bar, label in zip(bars, labels):\n",
    "        if oriented == 'v':\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(label,\n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 2),\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center')\n",
    "        else:\n",
    "            width = bar.get_width()\n",
    "            ax.annotate(label,\n",
    "                        xy=(width, bar.get_y() + bar.get_height() / 2),\n",
    "                        xytext=(1, 0),\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='left',\n",
    "                        va='center')\n",
    "\n",
    "def plot_correlation_matrix(ax, data, cmap='hot', diagonal=False, square=True, annotate=False, annot_kwargs=8):\n",
    "    mask = None\n",
    "    if diagonal:\n",
    "        mask = np.zeros_like(data, dtype=np.bool)\n",
    "        mask[np.triu_indices_from(mask)] = True\n",
    "    sns.heatmap(data, ax=ax,\n",
    "                mask=mask,\n",
    "                square=square,\n",
    "                linewidths=1.5,\n",
    "                cmap=cmap,\n",
    "                cbar_kws={'shrink': 1, 'ticks': [-1, -.5, 0, 0.5, 1]},\n",
    "                vmin=-1,\n",
    "                vmax=1,\n",
    "                annot=annotate,\n",
    "                annot_kws={'size': annot_kwargs})\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "    \n",
    "def plot_confusion_matrix(model, X, y, ax, normalize=True, title=None):\n",
    "    \"\"\"Plots confusion matrix\n",
    "    Parameters:\n",
    "    ax =  matplotlib axes\n",
    "    normalyze = normalization over truth (number_predicted / total_count_of_this_class)\n",
    "    \"\"\"\n",
    "    model.fit(X,y)\n",
    "    conf_matrix = metrics.confusion_matrix(y_true=y, y_pred=model.predict(X),\n",
    "                              labels=None)  # returns matrix for sorted classes (i.e 0, 1, 2,..., n)\n",
    "    classes = y.unique()\n",
    "    classes.sort()\n",
    "    n_classes = [len(y[y == c]) for c in classes]\n",
    "    if normalize == True:\n",
    "        n_matrix = [[i for j in range(len(n_classes))] for i in n_classes]\n",
    "        norm_matrix = conf_matrix / np.array(n_classes)\n",
    "        ns_matrix = np.array([[i for j in enumerate(n_classes)] for i in n_classes])\n",
    "        labels = np.array([[\"{0:.2%} \\n {1:d} of {2:d}\".format(norm_matrix[i, j], conf_matrix[i, j],\n",
    "                                                               ns_matrix[i, j]) for j, v in\n",
    "                            enumerate(norm_matrix[i])]\n",
    "                           for i, v in enumerate(norm_matrix)])\n",
    "\n",
    "        sns.heatmap(norm_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "    else:\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "    ax.set_ylabel('True Labels')\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    if title is None:\n",
    "        title = model.__class__.__name__\n",
    "    ax.set_title(title)\n",
    "    ttl = ax.title\n",
    "    ttl.set_position([.5, 1.07])\n",
    "\n",
    "    # fix for mpl bug that cuts off top/bottom of seaborn viz\n",
    "    b, t = ax.get_ylim()  # discover the values for bottom and top\n",
    "    b += 0.5  # Add 0.5 to the bottom\n",
    "    t -= 0.5  # Subtract 0.5 from the top\n",
    "    ax.set_ylim(b, t)  # update the ylim(bottom, top) values\n",
    "    \n",
    "def plot_mae_deciles(model, X, y_true, y_bl, index, ax, log_transform=False, cumulative=False, title=None, exp=True):\n",
    "    if exp==True:\n",
    "        y_pred = np.exp(model.predict(X)) - 1\n",
    "        y_true = np.exp(y_true.values) - 1\n",
    "        y_bl = np.exp(y_bl.values) - 1\n",
    "    else:\n",
    "        y_pred = model.predict(X)\n",
    "    y_mae_model = np.abs(y_true - y_pred)\n",
    "    y_mae_naive = np.abs(y_true - np.mean(y_bl))\n",
    "    y = np.stack([y_mae_model, y_mae_naive], axis=1)\n",
    "    y = pd.DataFrame(y, index=index, columns=['mae_model', 'mae_naive']).sort_values(by='mae_model', ascending=True)\n",
    "\n",
    "    y_dec = np.zeros(len(y_true))\n",
    "    n = len(y) // 10\n",
    "    N = 10 * n\n",
    "    for i in range(0, N, n):\n",
    "        if i/n==9:\n",
    "            y_dec[i:] = i/n\n",
    "        else:\n",
    "            y_dec[i:i+n] = i/n\n",
    "    y['deciles'] = y_dec\n",
    "    y['deciles'] = y['deciles'].astype('int32')\n",
    "\n",
    "    mae_model = []\n",
    "    mae_naive = []\n",
    "    dec_labs = y['deciles'].unique()\n",
    "    ax.set_xticks(np.arange(len(dec_labs)))\n",
    "    for i in dec_labs:\n",
    "        if cumulative:\n",
    "            mae_model.append(np.mean(y.loc[y['deciles']<=i, 'mae_model']))\n",
    "            mae_naive.append(np.mean(y.loc[y['deciles']<=i, 'mae_naive']))\n",
    "            ax.set_xticklabels(np.arange(10,110,10))\n",
    "            ax.set_xlabel('% of population')\n",
    "            ax.set_ylabel('Mean absolute error \\n (cumulative mean)')\n",
    "        else:\n",
    "            mae_model.append(np.mean(y.loc[y['deciles']==i, 'mae_model']))\n",
    "            mae_naive.append(np.mean(y.loc[y['deciles']==i, 'mae_naive']))\n",
    "            ax.set_xlabel('Deciles')\n",
    "            ax.set_ylabel('Mean absolute error \\n (mean per decile)')\n",
    "    data = np.stack([mae_model, mae_naive], axis=1)\n",
    "    data = pd.DataFrame(data, columns=['mae_model', 'mae_naive'])\n",
    "\n",
    "    _x = data.index\n",
    "    _y = data['mae_model'].values\n",
    "    ax.plot(_x, _y, marker='o', color='b')\n",
    "    \n",
    "    _y = data['mae_naive']\n",
    "    ax.plot(_x, _y, marker='o', color='r')\n",
    "    \n",
    "    ax.legend(['Model predictions', 'Naive predictions'])\n",
    "    spines = {'left': True,\n",
    "              'right': False,\n",
    "              'top': False,\n",
    "              'bottom': True}\n",
    "    for i in list(spines.keys()):\n",
    "        ax.spines[i].set_visible(spines[i])\n",
    "        \n",
    "    if log_transform:\n",
    "        ax.set_yscale('log')\n",
    "    \n",
    "    if title is None:\n",
    "        title = model.__class__.__name__\n",
    "    ax.set_title(title)\n",
    "    ttl = ax.title\n",
    "    ttl.set_position([.5, 1.05])\n",
    "    \n",
    "    ax.grid(True)\n",
    "                 \n",
    "    deciles = y['deciles']\n",
    "    if index is not None:\n",
    "        deciles.index = index\n",
    "        \n",
    "    return data, deciles\n",
    "\n",
    "def plot_sale_change_deciles(model, X, y_true, y_bl, index, ax, cumulative=False, title=None, colors=None, exp=True):\n",
    "    if exp==True:\n",
    "        y_pred = np.exp(model.predict(X)) - 1\n",
    "        y_true = np.exp(y_true.values) - 1\n",
    "    else:\n",
    "        y_pred = model.predict(X)\n",
    "    y_bl = np.exp(y_bl.values) - 1\n",
    "    \n",
    "    sale_change_pred = y_pred - y_bl\n",
    "    sale_change_true = y_true - y_bl\n",
    "    y = np.stack([sale_change_pred, sale_change_true], axis=1)\n",
    "    y = pd.DataFrame(y, index=index, columns=['sale_change_pred', 'sale_change_true']).sort_values(by='sale_change_pred', ascending=False)\n",
    "\n",
    "    y_dec = np.zeros(len(y_true))\n",
    "    n = len(y) // 10\n",
    "    N = 10 * n\n",
    "    for i in range(0, N, n):\n",
    "        if i/n==9:\n",
    "            y_dec[i:] = i/n\n",
    "        else:\n",
    "            y_dec[i:i+n] = i/n\n",
    "    y['deciles'] = y_dec\n",
    "    y['deciles'] = y['deciles'].astype('int32')\n",
    "\n",
    "    sale_change_pred = []\n",
    "    sale_change_true = []\n",
    "    dec_labs = y['deciles'].unique()\n",
    "    ax.set_xticks(np.arange(len(dec_labs)))\n",
    "    for i in dec_labs:\n",
    "        if cumulative:\n",
    "            sale_change_pred.append(np.mean(y.loc[y['deciles']<=i, 'sale_change_pred']))\n",
    "            sale_change_true.append(np.mean(y.loc[y['deciles']<=i, 'sale_change_true']))\n",
    "            ax.set_xticklabels(np.arange(10,110,10))\n",
    "            ax.set_xlabel('% of population', fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('Sales change \\n (mean per % of population)', fontsize=12, fontweight='bold')\n",
    "        else:\n",
    "            sale_change_pred.append(np.mean(y.loc[y['deciles']==i, 'sale_change_pred']))\n",
    "            sale_change_true.append(np.mean(y.loc[y['deciles']==i, 'sale_change_true']))\n",
    "            ax.set_xlabel('Deciles', fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('Sales change per advisor', fontsize=12, fontweight='bold')\n",
    "    data = np.stack([sale_change_pred, sale_change_true], axis=1)\n",
    "    data = pd.DataFrame(data, columns=['sale_change_pred', 'sale_change_true'])\n",
    "\n",
    "    _x = data.index\n",
    "    _y = data['sale_change_pred'].values\n",
    "    ax.plot(_x, _y, marker='o', color=('tab:blue' if colors is None else colors[0]))\n",
    "    \n",
    "    _y = data['sale_change_true']\n",
    "    ax.plot(_x, _y, marker='o', color=('tab:orange' if colors is None else colors[0]))\n",
    "    \n",
    "    ax.legend(['Predicted sales change', 'True sales change'])\n",
    "    spines = {'left': True,\n",
    "              'right': False,\n",
    "              'top': False,\n",
    "              'bottom': True}\n",
    "    for i in list(spines.keys()):\n",
    "        ax.spines[i].set_visible(spines[i])\n",
    "    \n",
    "    if title is None:\n",
    "        title = model.__class__.__name__\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ttl = ax.title\n",
    "    ttl.set_position([.5, 1.05])\n",
    "    \n",
    "    ax.grid(True)\n",
    "                 \n",
    "    deciles = y['deciles']\n",
    "    if index is not None:\n",
    "        deciles.index = index\n",
    "        \n",
    "    return data, deciles\n",
    "\n",
    "def plot_sales_deciles(model, X, y_true, index, ax, cumulative=False, log_transform=False, title=None, colors=None, exp=True):\n",
    "    if exp==True:\n",
    "        y_pred = np.exp(model.predict(X)) - 1\n",
    "        y_true = np.exp(y_true.values) - 1\n",
    "    else:\n",
    "        y_pred = model.predict(X)\n",
    "    y = np.stack([y_pred, y_true], axis=1)\n",
    "    y = pd.DataFrame(y, index=index, columns=['sales_pred', 'sales_true']).sort_values(by='sales_pred', ascending=False)\n",
    "\n",
    "    y_dec = np.zeros(len(y_true))\n",
    "    n = len(y) // 10\n",
    "    N = 10 * n\n",
    "    for i in range(0, N, n):\n",
    "        if i/n==9:\n",
    "            y_dec[i:] = i/n\n",
    "        else:\n",
    "            y_dec[i:i+n] = i/n\n",
    "    y['deciles'] = y_dec\n",
    "    y['deciles'] = y['deciles'].astype('int32')\n",
    "\n",
    "    sales_pred = []\n",
    "    sales_true = []\n",
    "    dec_labs = y['deciles'].unique()\n",
    "    ax.set_xticks(np.arange(len(dec_labs)))\n",
    "    for i in dec_labs:\n",
    "        if cumulative:\n",
    "            sales_pred.append(np.mean(y.loc[y['deciles']<=i, 'sales_pred']))\n",
    "            sales_true.append(np.mean(y.loc[y['deciles']<=i, 'sales_true']))\n",
    "            ax.set_xticklabels(np.arange(10,110,10))\n",
    "            ax.set_xlabel('% of population', fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('Sales \\n (mean per % of population)', fontsize=12, fontweight='bold')\n",
    "        else:\n",
    "            sales_pred.append(np.mean(y.loc[y['deciles']==i, 'sales_pred']))\n",
    "            sales_true.append(np.mean(y.loc[y['deciles']==i, 'sales_true']))\n",
    "            ax.set_xlabel('Deciles', fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('Sales per advisor', fontsize=12, fontweight='bold')\n",
    "    data = np.stack([sales_pred, sales_true], axis=1)\n",
    "    data = pd.DataFrame(data, columns=['sales_pred', 'sales_true'])\n",
    "\n",
    "    _x = data.index\n",
    "    _y = data['sales_pred'].values\n",
    "    ax.plot(_x, _y, marker='o', color=('tab:blue' if colors is None else colors[0]))\n",
    "    \n",
    "    _y = data['sales_true']\n",
    "    ax.plot(_x, _y, marker='o', color=('tab:orange' if colors is None else colors[0]))\n",
    "    \n",
    "    if log_transform:\n",
    "        ax.set_yscale('log')\n",
    "    \n",
    "    ax.legend(['Predicted sales', 'True sales'])\n",
    "    spines = {'left': True,\n",
    "              'right': False,\n",
    "              'top': False,\n",
    "              'bottom': True}\n",
    "    for i in list(spines.keys()):\n",
    "        ax.spines[i].set_visible(spines[i])\n",
    "    \n",
    "    if title is None:\n",
    "        title = model.__class__.__name__\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ttl = ax.title\n",
    "    ttl.set_position([.5, 1.05])\n",
    "    \n",
    "    ax.grid(True)\n",
    "                 \n",
    "    deciles = y['deciles']\n",
    "    if index is not None:\n",
    "        deciles.index = index\n",
    "        \n",
    "    return data, deciles\n",
    "\n",
    "def plot_deciles_data(data, figname='', color='dimgrey', plot_type='bar', trend_line=False, trend_order=1, trend_color='dimgrey', cumulative_pop=False, data_labels=False, x_label=None, y_label=None):\n",
    "    grd = list(data.columns)\n",
    "    grd_n = len(grd)\n",
    "    grd_cols_n = 2\n",
    "    grd_rows_n = int(math.ceil(grd_n / grd_cols_n))\n",
    "\n",
    "    plt_h = 4\n",
    "    plt_w = 12\n",
    "    \n",
    "    fig_ttl = plt.figure()\n",
    "    fig_ttl.set_size_inches(plt_w * grd_cols_n, 0.3)\n",
    "    ax0 = fig_ttl.add_subplot()\n",
    "    ax0.text(0.5, 0.5, figname, fontsize=18, horizontalalignment='center', verticalalignment='center')\n",
    "    ax0.axis('off')\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(plt_w * grd_cols_n, plt_h * grd_rows_n)\n",
    "    gs = gridspec.GridSpec(grd_rows_n, grd_cols_n, figure=fig, wspace=0.3, hspace=0.5)\n",
    "\n",
    "    for idx, col in enumerate(list(data.columns)):\n",
    "        if data_labels:\n",
    "            labs = ['{0:.2f}'.format(i) for i in data[col]]\n",
    "            bar_labels=[labs]\n",
    "        else:\n",
    "            bar_labels=None\n",
    "        \n",
    "        if cumulative_pop:\n",
    "            tick_labels = np.arange(10,110,10)\n",
    "        else:\n",
    "            tick_labels = list(data.index)\n",
    "        \n",
    "        if x_label is not None:\n",
    "            tick_axis_label = x_label\n",
    "        else:\n",
    "            tick_axis_label = ''\n",
    "        if y_label is not None:\n",
    "            length_label = y_label\n",
    "        else:\n",
    "            length_label = col\n",
    "        \n",
    "        if plot_type=='bar':\n",
    "            plot_bar_diagram(ax=fig.add_subplot(gs[idx]),\n",
    "                             data=data[col].to_frame().T,\n",
    "                             bar_labels=bar_labels,\n",
    "                             tick_labels = tick_labels,\n",
    "                             plots_labels=None,\n",
    "                             plots_colors=[color],\n",
    "                             width=0.3,\n",
    "                             trend_line=trend_line, \n",
    "                             trend_order=trend_order, \n",
    "                             trend_color=[trend_color],\n",
    "                             title=None,\n",
    "                             tick_axis_label=tick_axis_label,\n",
    "                             length_label=length_label,\n",
    "                             orient='v',\n",
    "                             spines={'top': False, 'right': False})\n",
    "        elif plot_type=='scatter':\n",
    "            ax=fig.add_subplot(gs[idx])\n",
    "            _x = tick_labels\n",
    "            _y = data[col].values\n",
    "            ax.scatter(_x, _y, marker='o', color=color)\n",
    "            z = np.polyfit(_x, _y, 2)\n",
    "            p = np.poly1d(z)\n",
    "            ax.plot(_x, p(_x), color=color)\n",
    "            \n",
    "def plot_diagram_xy(data, x, y, ax, x_title=None, y_title=None, x_labels_format='{0:.0f}', title=None, pot_size=None, tick_labelsIprefix=''):\n",
    "    _data = data.copy()\n",
    "    _data = _data.sort_values(by=x, ascending=False)\n",
    "    _data['deciles'] = pd.cut(_data[x], 10, labels=False, duplicates='drop')\n",
    "#     _dec = np.zeros(len(_data[x]))\n",
    "#     n = len(_data[x]) // 10\n",
    "#     N = 10 * n\n",
    "#     for i in range(0, N, n):\n",
    "#         if i/n==9:\n",
    "#             _dec[i:] = i/n\n",
    "#         else:\n",
    "#             _dec[i:i+n] = i/n\n",
    "#     _data['deciles'] = _dec\n",
    "#     _data['deciles'] = _data['deciles'].astype('int32')\n",
    "\n",
    "    cuts = _data['deciles'].unique()\n",
    "    _x = np.zeros(len(cuts))\n",
    "    _y = np.zeros(len(cuts))\n",
    "    for idx, i in enumerate(cuts):\n",
    "        _x[len(cuts)-1-idx] = np.mean(_data.loc[_data['deciles']==i, x])\n",
    "        _y[len(cuts)-1-idx] = np.mean(_data.loc[_data['deciles']==i, y])\n",
    "#     cuts = _data['deciles'].unique()\n",
    "#     _x = np.zeros(len(cuts))\n",
    "#     _y = np.zeros(len(cuts))\n",
    "#     for idx, i in enumerate(cuts):\n",
    "#         _x[len(cuts)-1-idx] = np.mean(_data.loc[_data['deciles']==i, x])\n",
    "#         _y[len(cuts)-1-idx] = np.mean(_data.loc[_data['deciles']==i, y])\n",
    "    plot_bar_diagram(ax=ax,\n",
    "                     data=pd.Series(_y).to_frame().T,\n",
    "                     tick_labels=[tick_labelsIprefix + x_labels_format.format(i) for i in _x],\n",
    "                     bar_labels=None,\n",
    "                     orient='v',\n",
    "                     width=0.3,\n",
    "                     title=('{0} vs {1}'.format(y,x) if title is None else title),\n",
    "                     length_label=(y if y_title is None else y_title),\n",
    "                     tick_axis_label=(x if x_title is None else x_title),\n",
    "                     plots_colors=['tab:blue'],\n",
    "                     spines={'top': False, 'right': False})\n",
    "    \n",
    "def plot_diagram_deciles(data, y, ax, x_title=None, y_title=None, title=None, pot_size=None):\n",
    "    _data = data.copy()\n",
    "    dec_labs = _data['deciles'].unique()\n",
    "    dec_mean = []\n",
    "    for i in dec_labs:\n",
    "        dec_samples = _data.loc[_data['deciles']==i]\n",
    "        n = len(dec_samples)\n",
    "        val_mean = np.mean(dec_samples[y])\n",
    "        dec_mean.append(val_mean)\n",
    "        \n",
    "    plot_bar_diagram(ax=ax,\n",
    "                     data=pd.Series(dec_mean).to_frame().T,\n",
    "                     tick_labels=[i for i in dec_labs],\n",
    "                     bar_labels=None,\n",
    "                     orient='v',\n",
    "                     width=0.3,\n",
    "                     title=('{0} vs {1}'.format(y,x) if title is None else title),\n",
    "                     length_label=(y if y_title is None else y_title),\n",
    "                     tick_axis_label=('Deciles' if x_title is None else x_title),\n",
    "                     plots_colors=['tab:blue'],\n",
    "                     spines={'top': False, 'right': False})\n",
    "    \n",
    "def get_lift_chart(model, data, X, by_class=1, exp=True):\n",
    "    _data = data.copy()\n",
    "    if exp==True:\n",
    "        y_pred = np.exp(model.predict(X)) - 1\n",
    "#         y_true = np.exp(y_true.values) - 1\n",
    "    else:\n",
    "        y_pred = model.predict(X)\n",
    "#     y = np.stack([y_true, y_pred], axis=1)\n",
    "#     y = pd.DataFrame(y, columns=['true_y', 'predicted_y']).sort_values(by='predicted_y', ascending=False)\n",
    "    _data['predicted_y'] = y_pred.reshape(-1,1)\n",
    "#     y = pd.DataFrame(y_pred.reshape(-1,1), columns=['predicted_y']).sort_values(by='predicted_y', ascending=False)\n",
    "    y = _data.sort_values(by='predicted_y', ascending=False)\n",
    "    y_dec = np.zeros(len(y))\n",
    "    n = len(y) // 10\n",
    "    N = 10 * n\n",
    "    for i in range(0, N, n):\n",
    "        if i/n==9:\n",
    "            y_dec[i:] = i/n\n",
    "        else:\n",
    "            y_dec[i:i+n] = i/n\n",
    "    y['deciles'] = y_dec\n",
    "    y['deciles'] = y['deciles'].astype('int32')\n",
    "\n",
    "    def val_cum(arr_n, arr_val, pos):\n",
    "        arr = []\n",
    "        for i in range(pos + 1):\n",
    "#             print(arr_val[i], arr_n[i])\n",
    "            arr.append(arr_val[i] * arr_n[i])\n",
    "        return np.sum(arr)\n",
    "\n",
    "    dec_labs = y['deciles'].unique()\n",
    "    total_mean = np.mean(y['predicted_y'])\n",
    "#     total_mean = np.sum(y['true_y']) / len(y)\n",
    "    n_samples = []\n",
    "    dec_mean = []\n",
    "#     dec_val_per_fa = []\n",
    "    dec_lift_ovr_mean = []\n",
    "    n_cum_samples = []\n",
    "    cum_mean = []\n",
    "#     cum_val_per_fa = []\n",
    "    cum_lift_ovr_mean = []\n",
    "    for i in dec_labs:\n",
    "        dec_samples = y.loc[y['deciles']==i]\n",
    "\n",
    "        n = len(dec_samples)\n",
    "        val_mean = np.mean(dec_samples['predicted_y'])\n",
    "#         val_sum = np.sum(dec_samples['predicted_y'])\n",
    "#         val_per_fa = val_sum / n\n",
    "        lift_ovr = val_mean / total_mean - 1\n",
    "#         lift_ovr = val_per_fa / total_mean - 1\n",
    "\n",
    "        n_samples.append(n)\n",
    "        dec_mean.append(val_mean)\n",
    "#         dec_val_per_fa.append(val_per_fa)\n",
    "        dec_lift_ovr_mean.append(lift_ovr)\n",
    "\n",
    "        n_cum = len(y.loc[y['deciles']<=i])\n",
    "#         mean_cum = (val_mean if i==0 else val_cum(n_samples, dec_mean, i) / n_cum)\n",
    "        mean_cum = np.sum(dec_mean)\n",
    "#         val_per_fa_cum = np.sum(dec_val_per_fa)\n",
    "        lift_ovr_cum = mean_cum / total_mean - 1\n",
    "#         lift_ovr_cum = val_per_fa_cum / total_mean - 1\n",
    "\n",
    "        n_cum_samples.append(n_cum)\n",
    "        cum_mean.append(mean_cum)\n",
    "#         cum_val_per_fa.append(val_per_fa_cum)\n",
    "#         cum_lift_ovr_mean.append(lift_ovr_cum)\n",
    "        cum_lift_ovr_mean.append(np.sum(dec_lift_ovr_mean))\n",
    "    lift = np.stack([n_samples, dec_mean, dec_lift_ovr_mean, n_cum_samples, cum_mean, cum_lift_ovr_mean], axis=1)\n",
    "    return y, total_mean, pd.DataFrame(lift, columns=['n_samples', 'dec_mean', 'dec_lift_ovr_mean', 'n_cum_samples', 'cum_mean', 'cum_lift_ovr_mean'])\n",
    "#     lift = np.stack([n_samples, dec_val_per_fa, dec_lift_ovr_mean, n_cum_samples, cum_val_per_fa, cum_lift_ovr_mean], axis=1)\n",
    "#     return total_mean, pd.DataFrame(lift, columns=['n_samples', 'dec_val_per_fa', 'dec_lift_ovr_mean', 'n_cum_samples', 'cum_val_per_fa', 'cum_lift_ovr_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Tune parameters\n",
    "def param_tune(model, X_train, y_train, param_ranges, scoring, cv, refit=''):\n",
    "    if refit == '': refit = list(scoring.keys())[0]\n",
    "    gsearch = model_selection.GridSearchCV(estimator=model, param_grid=param_ranges, scoring=scoring, cv=cv, refit=refit, return_train_score=True,\n",
    "                           n_jobs=-1)\n",
    "    gsearch.fit(X_train, y_train)\n",
    "    cv_res = pd.DataFrame(gsearch.cv_results_)\n",
    "    cv_res_sel = []\n",
    "    for i in list(scoring.keys()):\n",
    "        df = cv_res.loc[cv_res['rank_test_%s' % i] == 1].head(1)\n",
    "        cv_res_sel.append(df[['mean_train_%s' % i, 'std_train_%s' % i, 'mean_test_%s' % i, 'std_test_%s' % i]].values[0])\n",
    "\n",
    "    cv_res_sel = pd.DataFrame(cv_res_sel, index=list(scoring.keys()), columns=['mean_train', 'std_train', 'mean_test', 'std_test'])\n",
    "    cv_results = cv_res_sel.T\n",
    "    cv_results = cv_results.apply(lambda i: np.absolute(i))\n",
    "    return gsearch.best_estimator_, gsearch.best_params_, gsearch.best_score_, cv_results\n",
    "\n",
    "# Cross-validation report\n",
    "def cv_rep(model, X, y, cv, scoring, fit_params=None):\n",
    "    cv_res = model_selection.cross_validate(model, X, y, scoring=scoring, cv=cv, return_train_score=True, fit_params=fit_params, n_jobs=-1)\n",
    "    cv_res = [[np.mean(cv_res['train_%s' % i]), np.std(cv_res['train_%s' % i]), np.mean(cv_res['test_%s' % i]), np.std(cv_res['test_%s' % i])] for i in list(scoring.keys())]\n",
    "    cv_results = pd.DataFrame(cv_res, index=list(scoring.keys()), columns=['mean_train', 'std_train', 'mean_test', 'std_test'])\n",
    "    cv_results = cv_results.T\n",
    "    cv_results = cv_results.apply(lambda i: np.absolute(i))\n",
    "    return cv_results\n",
    "\n",
    "# Tune model parameters and print CV report\n",
    "def train_best_model(model, param_ranges, X_train, y_train, scoring, cv, refit):\n",
    "    model, best_params, best_score, cv_res = param_tune(model, X_train, y_train, param_ranges, scoring, cv, refit=refit)\n",
    "    print('CV results \\n ===================================================')\n",
    "    display(cv_res)\n",
    "    print('\\n Best parameters: ', best_params)\n",
    "    return model, cv_res\n",
    "\n",
    "# Tune model parameters and print CV report for calibrated classifier model\n",
    "def train_best_model_cal(model, param_ranges, X_train, y_train, scoring, cv, refit):\n",
    "    if model.__class__.__name__=='CalibratedClassifierCV':\n",
    "         model_cal= model \n",
    "    else:\n",
    "        model_cal = calib.CalibratedClassifierCV(base_estimator=model, method='sigmoid', cv=cv)\n",
    "    model_cal, best_params, best_score, cv_res = param_tune(model_cal, X_train, y_train, param_ranges, scoring, cv, refit=refit)\n",
    "    print(cv_res)\n",
    "    print(best_params)\n",
    "    return model, cv_res\n",
    "\n",
    "def dropcol_imp_r2_metric(model, X_valid, y_valid, sample_weights):\n",
    "    y_pred = model.predict(X_valid)\n",
    "    return metrics.r2_score(y_valid, y_pred, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading sheet Transactions18\n"
     ]
    }
   ],
   "source": [
    "data_2018 = pd.read_excel(io='Data/Transaction Data.xlsx',\n",
    "                     sheet_name='Transactions18',\n",
    "                     header=0,\n",
    "                     index_col=0,\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading sheet Transactions19\n"
     ]
    }
   ],
   "source": [
    "data_2019 = pd.read_excel(io='Data/Transaction Data.xlsx',\n",
    "                     sheet_name='Transactions19',\n",
    "                     header=0,\n",
    "                     index_col=0,\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading sheet Transactions19\n"
     ]
    }
   ],
   "source": [
    "data_2019 = pd.read_excel(io='Data/Transaction Data.xlsx',\n",
    "                     sheet_name='Transactions19',\n",
    "                     header=0,\n",
    "                     index_col=0,\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading sheet Rep summary\n"
     ]
    }
   ],
   "source": [
    "data_firm = pd.read_excel(io='Data/Firm Information-1.xlsx',\n",
    "                     sheet_name='Rep summary',\n",
    "                     header=0,\n",
    "                     index_col=0,\n",
    "                     verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop refresh date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018 = data_2018.drop(columns=['refresh_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2019 = data_2019.drop(columns=['refresh_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2019.columns = [i + '_target' for i in list(data_2019.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2019 = data_2019.loc[data_2018.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_firm = data_firm[['Channel', 'Sub channel', 'Firm name']].loc[data_2019.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data_2018, data_2019, data_firm], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deal with NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data is numeric and and naturaly is equal or more than zero. So will fill nans with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop samples that have negative sales and positive redemptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales_12M_target 2\n",
      "AUM 4377\n",
      "sales_curr 4\n",
      "sales_12M 7\n",
      "aum_AC_EQUITY 3871\n",
      "aum_AC_FIXED_INCOME_MUNI 3276\n",
      "aum_AC_FIXED_INCOME_TAXABLE 1694\n",
      "aum_AC_MULTIPLE 1149\n",
      "aum_AC_PHYSICAL_COMMODITY 90\n",
      "aum_AC_REAL_ESTATE 3\n",
      "aum_AC_TARGET 19\n",
      "aum_P_529 14\n",
      "aum_P_ETF 5\n",
      "aum_P_MF 4564\n",
      "aum_P_SMA 1151\n",
      "aum_P_UCITS 15\n",
      "aum_P_UIT 42\n"
     ]
    }
   ],
   "source": [
    "# Inspect positive variables\n",
    "f_pos = ['sales_12M_target',\n",
    "         'AUM', \n",
    "         'sales_curr',         \n",
    "         'sales_12M',\n",
    "         'aum_AC_EQUITY',\n",
    "         'aum_AC_FIXED_INCOME_MUNI',\n",
    "         'aum_AC_FIXED_INCOME_TAXABLE',\n",
    "         'aum_AC_MULTIPLE',\n",
    "         'aum_AC_PHYSICAL_COMMODITY',\n",
    "         'aum_AC_REAL_ESTATE',\n",
    "         'aum_AC_TARGET',\n",
    "         'aum_P_529',\n",
    "         'aum_P_ETF',\n",
    "         'aum_P_MF',\n",
    "         'aum_P_SMA',\n",
    "         'aum_P_UCITS',\n",
    "         'aum_P_UIT']\n",
    "\n",
    "for i in f_pos:\n",
    "    print(i, len(data.loc[data[i] < 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redemption_curr 3\n",
      "redemption_12M 4\n"
     ]
    }
   ],
   "source": [
    "# Inspect negative variables\n",
    "f_neg = ['redemption_curr',\n",
    "'redemption_12M']\n",
    "\n",
    "for i in f_neg:\n",
    "    print(i, len(data.loc[data[i] > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[(data['sales_12M']>=0) & \n",
    "         (data['sales_12M_target']>=0) & \n",
    "         (data['sales_curr']>=0) & \n",
    "         (data['redemption_curr']<=0) & \n",
    "         (data['redemption_12M']<=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reverse redemptions sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in f_neg:\n",
    "    data[i] = data[i].apply(np.abs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add delta_sales = sales_12M_2019 - sales_12M_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['delta_sales_12M_18_19'] = (data['sales_12M_target'] - data['sales_12M'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add net sales data (net_sales = sales - redumptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_cols = {'net_no_of_sales_12M_1': ['no_of_sales_12M_1', 'no_of_Redemption_12M_1'], \n",
    "            'net_no_of_sales_12M_10K': ['no_of_sales_12M_10K', 'no_of_Redemption_12M_10K'], \n",
    "            'net_no_of_funds_sold_12M_1': ['no_of_funds_sold_12M_1', 'no_of_funds_redeemed_12M_1'], \n",
    "            'net_no_of_fund_sales_12M_10K': ['no_of_fund_sales_12M_10K', 'no_of_funds_Redemption_12M_10K'], \n",
    "            'net_no_of_assetclass_sold_12M_1': ['no_of_assetclass_sold_12M_1', 'no_of_assetclass_redeemed_12M_1'], \n",
    "            'net_no_of_assetclass_sales_12M_10K': ['no_of_assetclass_sales_12M_10K', 'no_of_assetclass_Redemption_12M_10K']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for net_col in net_cols.keys():\n",
    "    data[net_col] = data[net_cols[net_col][0]] - data[net_cols[net_col][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['net_sales_curr'] = data['sales_curr'] - data['redemption_curr']\n",
    "data['net_sales_12M'] = data['sales_12M'] - data['redemption_12M']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split aum columns into positive and negative columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "aum_cols = []\n",
    "for i in list(data.columns):\n",
    "    if 'aum' in i:\n",
    "        aum_cols.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aum_col in aum_cols:\n",
    "    data['pos_' + aum_col] = data[aum_col].apply(lambda x: x if x >= 0 else 0)\n",
    "    data['neg_' + aum_col] = data[aum_col].apply(lambda x: np.abs(x) if x < 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pos_AUM'] = data['AUM'].apply(lambda x: x if x >= 0 else 0)\n",
    "data['neg_AUM'] = data['AUM'].apply(lambda x: np.abs(x) if x < 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split net columns into positive and negative columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for net_col in list(net_cols.keys()) + ['net_sales_curr', 'net_sales_12M']:\n",
    "    data['pos_' + net_col] = data[net_col].apply(lambda x: x if x >= 0 else 0)\n",
    "    data['neg_' + net_col] = data[net_col].apply(lambda x: np.abs(x) if x < 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['National Broker-Dealer',\n",
       " 'Dual',\n",
       " 'Independent Dealer',\n",
       " 'International Outlet',\n",
       " 'Fee-Based Adviser',\n",
       " 'Bank/Trust',\n",
       " 'Private Client Group',\n",
       " 'Discount',\n",
       " 'Networker',\n",
       " 'Asset Manager',\n",
       " 'Low/Non Producer']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data['Channel'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_deciles_reg = pd.read_csv('Sales_reg_test_data_deciles.csv', index_col=0)\n",
    "test_data_deciles_cls = pd.read_csv('NewFund_clc_test_data_deciles.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_deciles_reg[['Channel', 'Sub channel', 'Firm name']] = data.loc[test_data_deciles_reg.index][['Channel', 'Sub channel', 'Firm name']]\n",
    "test_data_deciles_cls[['Channel', 'Sub channel', 'Firm name']] = data.loc[test_data_deciles_cls.index][['Channel', 'Sub channel', 'Firm name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_decile_1 = test_data_deciles_reg.loc[test_data_deciles_reg['deciles']==0]\n",
    "cls_decile_1 = test_data_deciles_cls.loc[test_data_deciles_cls['deciles']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_vals(data, col):\n",
    "    N = len(data)\n",
    "    df = []\n",
    "    df_index = list(data[col].unique())\n",
    "    for channel in df_index:\n",
    "        df.append(len(data.loc[data[col]==channel]) / N)\n",
    "    return pd.DataFrame(np.array(df).reshape(-1,1), index=df_index, columns=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Networker</th>\n",
       "      <td>0.008547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Independent Dealer</th>\n",
       "      <td>0.521368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>National Broker-Dealer</th>\n",
       "      <td>0.405983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fee-Based Adviser</th>\n",
       "      <td>0.014957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dual</th>\n",
       "      <td>0.032051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bank/Trust</th>\n",
       "      <td>0.012821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Private Client Group</th>\n",
       "      <td>0.002137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discount</th>\n",
       "      <td>0.002137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Channel\n",
       "Networker               0.008547\n",
       "Independent Dealer      0.521368\n",
       "National Broker-Dealer  0.405983\n",
       "Fee-Based Adviser       0.014957\n",
       "Dual                    0.032051\n",
       "Bank/Trust              0.012821\n",
       "Private Client Group    0.002137\n",
       "Discount                0.002137"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df_vals(reg_decile_1, 'Channel')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = df.loc[df[0]>0.1]\n",
    "# df2 = df.loc[df[0]<0.1]\n",
    "\n",
    "# df3 = df1.append([df2.sum().sum()])\n",
    "# df3.index = list(df1.index) + ['Others']\n",
    "\n",
    "# df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = df3.plot.pie(y=0, figsize=(8, 8), legend=False)\n",
    "# plt.savefig('temp.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Firm name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>U.S. Bank Private Wealth Management</th>\n",
       "      <td>0.008547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raymond James Financial Services, Inc.</th>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Merrill Lynch</th>\n",
       "      <td>0.181624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ameriprise Financial Services, Inc.</th>\n",
       "      <td>0.085470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morgan Stanley Wealth Management</th>\n",
       "      <td>0.143162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PNC Bank, NA</th>\n",
       "      <td>0.002137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MML Investors Services, LLC</th>\n",
       "      <td>0.002137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>William Blair &amp; Co.</th>\n",
       "      <td>0.002137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U.S. Bancorp Wealth Management</th>\n",
       "      <td>0.002137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Triad Advisors Inc.</th>\n",
       "      <td>0.002137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Firm name\n",
       "U.S. Bank Private Wealth Management      0.008547\n",
       "Raymond James Financial Services, Inc.   0.025641\n",
       "Merrill Lynch                            0.181624\n",
       "Ameriprise Financial Services, Inc.      0.085470\n",
       "Morgan Stanley Wealth Management         0.143162\n",
       "...                                           ...\n",
       "PNC Bank, NA                             0.002137\n",
       "MML Investors Services, LLC              0.002137\n",
       "William Blair & Co.                      0.002137\n",
       "U.S. Bancorp Wealth Management           0.002137\n",
       "Triad Advisors Inc.                      0.002137\n",
       "\n",
       "[72 rows x 1 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df_vals(reg_decile_1, 'Firm name')\n",
    "df.to_csv('temp.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sub channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USBT</th>\n",
       "      <td>0.008547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IBD</th>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NACS</th>\n",
       "      <td>0.549145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIA</th>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sub channel\n",
       "USBT     0.008547\n",
       "IBD      0.416667\n",
       "NACS     0.549145\n",
       "RIA      0.025641"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df_vals(reg_decile_1, 'Sub channel')\n",
    "# df.to_csv('temp.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Independent Dealer</th>\n",
       "      <td>0.575107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Networker</th>\n",
       "      <td>0.002146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>National Broker-Dealer</th>\n",
       "      <td>0.360515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fee-Based Adviser</th>\n",
       "      <td>0.032189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Private Client Group</th>\n",
       "      <td>0.004292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dual</th>\n",
       "      <td>0.019313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bank/Trust</th>\n",
       "      <td>0.006438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Channel\n",
       "Independent Dealer      0.575107\n",
       "Networker               0.002146\n",
       "National Broker-Dealer  0.360515\n",
       "Fee-Based Adviser       0.032189\n",
       "Private Client Group    0.004292\n",
       "Dual                    0.019313\n",
       "Bank/Trust              0.006438"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df_vals(cls_decile_1, 'Channel')\n",
    "# df.to_csv('temp.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Firm name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LPL Financial LLC</th>\n",
       "      <td>0.064378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Commonwealth Financial Network</th>\n",
       "      <td>0.012876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U.S. Bank Private Wealth Management</th>\n",
       "      <td>0.002146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NYLife Securities LLC</th>\n",
       "      <td>0.002146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ameriprise Financial Services, Inc.</th>\n",
       "      <td>0.077253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D.A. Davidson &amp; Co. Inc.</th>\n",
       "      <td>0.004292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUSO Financial Services, LP</th>\n",
       "      <td>0.002146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SunTrust Investment Services, Inc.</th>\n",
       "      <td>0.004292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Park Avenue Securities LLC</th>\n",
       "      <td>0.002146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Citi PWM</th>\n",
       "      <td>0.002146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Firm name\n",
       "LPL Financial LLC                     0.064378\n",
       "Commonwealth Financial Network        0.012876\n",
       "U.S. Bank Private Wealth Management   0.002146\n",
       "NYLife Securities LLC                 0.002146\n",
       "Ameriprise Financial Services, Inc.   0.077253\n",
       "...                                        ...\n",
       "D.A. Davidson & Co. Inc.              0.004292\n",
       "CUSO Financial Services, LP           0.002146\n",
       "SunTrust Investment Services, Inc.    0.004292\n",
       "Park Avenue Securities LLC            0.002146\n",
       "Citi PWM                              0.002146\n",
       "\n",
       "[69 rows x 1 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df_vals(cls_decile_1, 'Firm name')\n",
    "df.to_csv('temp.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sub channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IBD</th>\n",
       "      <td>0.474249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USBT</th>\n",
       "      <td>0.002146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NACS</th>\n",
       "      <td>0.510730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RIA</th>\n",
       "      <td>0.012876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sub channel\n",
       "IBD      0.474249\n",
       "USBT     0.002146\n",
       "NACS     0.510730\n",
       "RIA      0.012876"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df_vals(cls_decile_1, 'Sub channel')\n",
    "# df.to_csv('temp.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
